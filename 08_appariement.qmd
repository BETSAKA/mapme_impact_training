---
output: html_document
editor_options: 
  chunk_output_type: console
---

# Méthodes d'appariement


<iframe src="slides/fr/matching.html" width="100%" height="400px">

</iframe>

## La question de la comparabilité des groupes

On a vu dans le chapitre précédent que les comparaisons simples réalisées entre les premières et les dernières aires à avoir été formellement protégées pose problème.

On va maintenant chercher à renforcer la comparabilité entre le groupe de traitement et le groupe de contrôle en réalisant un appariemment (cf. diapos de présentation).

On va utiliser le package {MatchIt} : ne pas hésiter à se référer à [la documentation du package](https://kosukeimai.github.io/MatchIt/index.html).

On va commencer par réaliser quelques ajustements, car {MatchIt} requiert qu'aucune valeur des variables mobilisées ne soit manquante. On va donc retirer les observations comportant des `NA`.

```{r, output = FALSE}
library(tidyverse) # Simplifie la manipulation de données
library(lubridate) # Simplifie les opérations sur des dates
library(sf) # Pour traiter les données spatiales
library(MatchIt) # Pour réaliser les appariements.
library(cobalt) # Pour les tests d'équilibre sur l'appariement
library(gt) # Pour faire de jolies tables
library(stargazer) # Pour présenter les résultats de régressions
library(mapme.biodiversity)
library(htmltools)

# Désactiver les notations scientifiques
options(scipen = 999)

# Charger les données
AP_Vahatra <- read_rds("data/AP_Vahatra_mapme.rds") %>%
  portfolio_wide() %>%
  mutate(Groupe = ifelse(year(date_creation) < 2015, "Traitement", "Contrôle"))

# Préparer les données sans valeurs manquantes
Vahatra_defor_noNA <- AP_Vahatra %>%
  mutate(surface_ha = as.numeric(st_area(AP_Vahatra)) / 10000, 
         couv_foret_2000 = `treecover_area_2000-01-01_treecover_ha` / surface_ha * 100,
         altitude = `elevation_2000-02-01_elevation_mean_m`,
         indice_accidente = `slope_2000-02-01_slope_mean_degrees`,
         dist_ville = `traveltime_2015-01-01_5k_110mio_traveltime_mean_minutes`,
         traitement = ifelse(year(date_creation) < 2015, 1, 0),
         taux_deforestation_2000_2014 = 
           -((`treecover_area_2014-01-01_treecover_ha` / 
              `treecover_area_2000-01-01_treecover_ha`)^(1/14) - 1) * 100) %>%
  filter(!is.na(couv_foret_2000), !is.na(dist_ville), !is.na(altitude), !is.na(indice_accidente))

summary(Vahatra_defor_noNA)

Vahatra_defor_noNA %>%
  st_drop_geometry() %>%
  group_by(Groupe, traitement) %>%
  summarise(effectif = n())
```
```{r}
Vahatra_defor_noNA %>%
  st_drop_geometry() %>%
  group_by(Groupe) %>%
  summarize(`Nombre d'aires protégées` = n()) %>%
  gt() %>%
  tab_header("Observations par groupe avant appariemment") %>%
  tab_source_note("Source : Association Vahatra et données GFC")
```

## Mesure de la propension

Pour commencer, nous allons spécifier le modèle probit qui estime dans quelle mesure la propension pour une aire d'avoir été protégée avant 2015 dépend de sa taille, de son taux de couverture forestière en 2000, de son altitude, de son caractère accidenté et de sa distance d'une ville d'au moins 5000 habitants.

Cette spécification peut se représenter selon l'équation suivante qui représente un modèle probit. Un modèle probit, tout comme le logit, est un modèle de choix binaire.

```{r}
# Spécification du modèle probit
pscor <- traitement ~  surface_ha + 
                       couv_foret_2000 + 
                       altitude +
                       indice_accidente + 
                       dist_ville
```

On va maintenant réaliser une régression pour connaître l'influence de ces facteurs dans la désignation des aires comme protégées.

```{r, output = FALSE}
# Régression probit
reg_select <- glm(formula = pscor,
                  family = binomial(link = "probit"),
                  data = Vahatra_defor_noNA)

match_out1 <- stargazer(reg_select, type = "html") 
```
```{r, echo = FALSE}
# On fait un rendu en html (en 2 fois pour régler la largeur)
out_html1 <- browsable(HTML(paste(match_out1, collapse = "")))
browsable(div(style = "width: 300px;", out_html1))
```

> Exercice : analysez ce résultat. Quels facteurs sont corrélés avec la désignation précoce comme aire protégée ?

## Appariement sur score de propension

On va maintenant utiliser ce modèle pour comparer les aires protégées traitées en premier par rapport à celles traitées plus récemment.

```{r}
# Calcul du matching
def_00_14_match <- matchit(formula = pscor,
                           family = binomial(link = "probit"),
                           method = "nearest",
                           discard = "both",
                           replace = FALSE,
                           distance = "glm",
                           data = Vahatra_defor_noNA)

print(def_00_14_match)
```

On peut maintenant observer les équilibres entre les groupes traités et contrôle avant et après l'appariement.

```{r}
summary(def_00_14_match)
```

> **Exercice** : Étudiez les tables ci-dessus. Quel effet a eu l'appariement sur l'équilibre des variables entre le groupe de traitement et le groupe de contrôle ? Combien d'observations ont été écartées ?

On peut observer la distance entre groupe de traitement et de contrôle.

```{r}
plot(def_00_14_match, type = "jitter", interactive = FALSE)
```

On peut également représenter l'équilibre entre les variables avant et après traitement avec les graphiques suivants.

```{r}
bal.plot(def_00_14_match, var.name = "dist_ville", which = "both")
```

> Exercice : Quel effet a eu l'appariement sur la variable de distance à la ville ? Les autres variables d'appariement produisent-elles un effet aussi visible ?

## Estimation du résultat en contrôlant pour les variables d'appariement

Le modèle qu'on utilise pour estimer l'impact est très proche de celui exposé ci-dessus, à la différence que la variable de traitement passe dans la partie droite, et qu'elle est remplacée par la déforestation.

```{r}
# Spécification du modèle pour l'impact
estimp <- taux_deforestation_2000_2014 ~   
                          traitement +
                          surface_ha + 
                          couv_foret_2000 + 
                          altitude +
                          indice_accidente + 
                          dist_ville
```

On va donc réaliser une régression, en tenant compte des pondérations générées par l'algorithme d'appariement (variable "weight").

```{r, output = FALSE}
# On extrait les données de l'appariement
def_00_14_match_data <- match.data(def_00_14_match)

# Régression avec pondérations
def_00_14_match_est <- lm(formula = estimp,
                          data = def_00_14_match_data,
                          weights = weights)

# Présentation des résultats
match_out2 <- stargazer(def_00_14_match_est, type = "html")
```
```{r, echo = FALSE}
# On fait un rendu en html (en 2 fois pour régler la largeur)
out_html2 <- browsable(HTML(paste(match_out2, collapse = "")))
browsable(div(style = "width: 500px;", out_html2))
```

## Exercices

### Exercice simple

Analysez, interprétez et critiquez les résultats ci-dessus.

### Exercice intermédiaire

Ajoutez des variables d'intérêt et modifiez les paramètres de la fonction de matching.

### Exercice avancé

Réalisez une analyse analogue avec les données de feux. Rédigez une analyse interprétative.

