---
output: html_document
editor_options: 
  chunk_output_type: console
---

# Préparation des données

## La fabrique des données

Que l'on cherche à quantifier la biodiversité, à mesurer la pauvreté, ou à évaluer l'impact de certaines interventions, il est indispensable non seulement comprendre d'où proviennent les données et comment elles sont produites, mais aussi d'entretenir une distance critique vis-à-vis de ces données, reconnaissant les potentiels biais et limites. Pour assurer une utilisation optimale des données, il est essentiel de comprendre non seulement leur origine, mais aussi les implications éthiques, politiques et sociales qui les entourent.

<iframe src="https://fbedecarrats.github.io/class_polecon_of_numbers_fr/" width="100%" height="400px">

</iframe>

https://fbedecarrats.github.io/class_polecon_of_numbers_fr/

Ce diaporama propose un éclarage sur le mdode de production données relatives aux aires protégées, à la forêt et à la biodiversité. Il met l'accent sur les méthodologies d'acquisition et d'analyse, pour prendre du recul dans linterprétation de ces données cruciales.

<iframe src="presentations/TVM2022_PresentationDesDonnees.pdf" width="100%" height="400px">

</iframe>

![Cliquer ici pour télécharger la présentationz](presentations/TVM2022_PresentationDesDonnees.pdf)

## Import des données géospatiales

On va cette fois-ci importer les données avec l'information géographique
:

-   Données Vahatra

```{r}
# On importe dans R en pointant vers le fichier .geojson
AP_Vahatra <- st_read("data/AP_Vahatra.geojson") 
```

-   Les limites communales :

```{r}
library(geodata)

# On enregistre les limites communales 
contour_mada <- gadm(country = "Madagascar", resolution = 1, level = 3,
                     path = "data/GADM") %>%
  st_as_sf()

# On enregistre contour_mada pour s'en servir par la suite
save(contour_mada, file = "data/contour_mada.rds")
```

### Le système de coordonnées de référence (SCR)

Le **Système de Coordonnées de Référence** (SCR) est un élément
fondamental lors du travail avec des données géospatiales.

C'est un ensemble de conventions qui spécifie comment les coordonnées
géodésiques (latitude, longitude, altitude) sont représentées et
mesurées sur un plan cartographique (une carte, un système de
coordonnées projetées).

Les SCR sont basés sur un **système de référence géodésique**, mais ils
introduisent des transformations et des projections pour représenter les
coordonnées de manière plus pratique sur une surface plane. Un SCR est
défini par la forme de l'ellipsoïde, l'origine du système de coordonnées
et l'orientation de ses axes par rapport à l'ellipsoïde.

Par exemple, pour le système de référence WGS84, l'origine du WGS 84
(World Geodetic System 1984) est située à l'intersection de l'équateur
(latitude 0 degrés) et du méridien de Greenwich (longitude 0 degrés)

![](figs/vector_lonlat_1.png)

De nombreux pays et organisations ont leurs propres systèmes de
référence géodésique, (ci-dessous un exemple) mais il existe également
des systèmes de référence géodésique mondiaux, tels que le WGS 84 (World
Geodetic System 1984), qui servent de norme internationale pour la
cartographie et la géolocalisation.

Il faut veiller à ce que nos **systèmes de coordonnées de références**.
La fonction st_crs() fait partie du package sf()et permet de vérifier ce
dernier.

```{r}
# On fait un point sur nos trois jeux de données 
st_crs(contour_mada) # WGS 84, EPSG:4326
st_crs(WDPA_Mada) # WGS 84, EPSG:4326 
st_crs(AP_Vahatra) # WGS 84, EPSG:4326 
```

### Les différents types de géométries

```{r}
# | tbl-cap: "Caractéristiques spatiales des données d'aires protégées WDPA du Sénégal"

# On crée une colonne pour connaître la géométrie de chaque observation (mutate) 
# On trie les données en fonction de leur géométrie (group_by) 
# On résume l'effectif total pour chaque catégorie de géométrie (summarise). 

WDPA_Mada %>%
  mutate(geom_type = st_geometry_type(.)) %>%  
  group_by(geom_type) %>%  
  summarise(n = n())  %>%
  st_drop_geometry() %>%
  gt() 

```

### Production d'une carte interactive

```{r}
library(tmap)
# On fait une carte pour visualiser la donnée géographique

tmap_mode("view") # En mode interactif
tm_shape(contour_mada) +
  tm_borders() +
  tm_shape(AP_Vahatra) + 
  tm_polygons(col = "cat_iucn", alpha = 0.6, title = "Catégorie IUCN",
              id = "nom",
              popup.vars = c("Acte de création" = "creation",
                             "Année de création" = "an_creation",
                             "Surface (ha)" = "hectares",
                             "Nom" = "nom",
                             "Gestionnaire" = "gest_1")) +
  tmap_options(check.and.fix = TRUE)

```

> Exercice : faire une carte avec les données WDPA

### Visualiser les différences entre les données Vahatra et WDPA

```{r}
WDPA_exclu <- WDPA_Mada %>%
  filter(!(NAME %in% AP_Vahatra$nom_wdpa))

tmap_mode("view")
WDPA_exclu %>%
  tm_shape() +
  tm_polygons(col = "IUCN_CAT")
```

### Les différents traitements géospatiaux

Le package sf() permet une multitude d'opérations géospatiales entre
deux catégories de données que l'on peut retrouver dans le cheat-sheep.

![](figures/overlay_operations.png)

Voici quelques exemples utiles qui font appel à ces fonctions.

```{r}
# Garder un seul type de géométrie dans le jeu de données 
# Ici, on ne garde que les polygones (sans les points)
WDPA_Mada_poly <- WDPA_Mada %>% 
  filter(st_geometry_type(.) == "MULTIPOLYGON")

# Couper ma couche avec les limites des communes 
# On ne garde donc que les parties terrestres
WDPA_Mada_poly_terrestre <- WDPA_Mada_poly %>%
  st_intersection(contour_mada)

# Calculer le total des surfaces de chaque aire
surface_cumul <- WDPA_Mada_poly_terrestre %>%
  mutate(surface = st_area(.)) %>% #le pçint fait référence à la géométrie de chaque objet spatial 
  st_drop_geometry() %>% 
  summarise(surface = sum(surface, na.rm = TRUE)) %>%
  mutate(`Type de cumul` = "Somme des surfaces terrestres de chaque aire protégée",
         .before = everything())
```

# Exercices pratiques à partir de R et mapme.biodiversity

On va ici mobiliser une série de packages pour la manipulation des données tabulaires et spatiale, pour leur restitution graphique, mais surtout oour l'acquisition et le traitement de données spatiales.

```{r}
library(tidyverse) # Une série de packages pour faciliter la manipulation de données
library(sf)
library(tmap)
# library(geodata)
# library(wdpar)
library(gt)
library(mapme.biodiversity)
library(progressr)
```

# Aires protégées

Les études sur les aires protégées s'appuient fréquemment sur la base WDPA (World Database on Protected Area), consultable en ligne sur https://protectedplanet.net. On s'aperçoit dans le cas de Madagascar que cette base de données comporte de nombreuses erreurs (qu'on étudiera plus bas). La base rassemblée par l'association Vahatra dans le cadre de la monographie qu'elle a coordonnée sur l'ensemble des aires protégées terrestres malgaches semble beaucoup plus fiable [@goodman_les_2018]. Les données en question sont disponibles sur le portail https://protectedareas.mg avec une licence creative commons (CC-BY).

Les données chargées ont été préalablement reformatée.

```{r}
# On charge la version enregistrée en geojson
AP_Vahatra <- st_read("data/AP_Vahatra.geojson")

# On génère un rendu cartographique
tmap_mode("view") # En mode interactif

tm_shape(AP_Vahatra) + 
  tm_polygons(col = "cat_iucn", alpha = 0.6, title = "Catégorie IUCN",
              id = "nom",
              popup.vars = c("Acte de création" = "creation",
                             "Année de création" = "an_creation",
                             "Surface (ha)" = "hectares",
                             "Nom complet" = "full_name",
                             "Gestionnaire" = "gest_1")) +
  tmap_options(check.and.fix = TRUE)
```

## Ancienneté des aires protégées

On réalise un graphique qui présente l'historique de création des aires protégées.

```{r}
# On modifie la variable "nom" pour qu'elle soit ordonnée par date de création
AP_Vahatra <- AP_Vahatra %>%
  mutate(nom = reorder(nom, desc(date_creation)))

# Un premier graphique simple avec des points
AP_Vahatra %>%
  ggplot(aes(x = date_creation, y = nom, color = cat_iucn)) +
  geom_point()

# avec des segments partant de la date de création jusqu'à aujourd'hui
AP_Vahatra %>%
  ggplot(aes(x = date_creation, y = nom, color = cat_iucn)) +
  geom_segment(aes(xend = ymd("2023-10-01"), yend = nom), linewidth = 2)
```

## Taille des aires protégées

> Réalisez un graphique équivalent pour la taille des aires protégées

### Le package mapme.biodiversity

Le package "mapme.biodiversity" facilite l'analyse de données statistiques sur les aires protégées partout dans le monde [@mapme.biodiversity]. Il permet l'**importation d'un nombre important de base de données et le calcul d'indicateurs associés relatifs à la biodiversité** qui peuvent être utilisés pour surveiller et évaluer l'efficacité des efforts de protection. Le processus est volontairement simple :

```{mermaid diagram_mapme}
#| fig-cap: "Processus de traitement avec mapme.biodiversity"

graph TB
    AA(Définition des polygones d'analyse)
    A(Initialisation du portefeuille)
    B(Acquisition des ressources)
    C(Calcul des indicateurs)
    D(Analyse statistique avec R)
    E(Export vers QGIS ou autre)
    AA-->A
    A-->B
    B-->C
    C-->D
    C-->E
```

La liste des ressources disponibles et des indicateurs peut être consultée [en ligne dans la documentation du package mapme.biodiversity](https://mapme-initiative.github.io/), ou dans R, via l'aide ou encore avec les fonctionns suivantes :

```{r}
available_resources() %>%
  gt()

available_indicators() %>%
  gt()
```

Nous sommes maintenant prêts à ajouter des variables. On va commencer par spécifier des options.

```{r}
mapme_options(outdir = "data/mapme_biodiversity"),
                               add_resources = TRUE)
```

Nous pouvons ensuite demander le téléchargement d'une ressource nécessaire pour calculer des indicateurs spécifiques. Une fois l'indicateur calculé individuellement pour tous les actifs d'un portefeuille, les données sont renvoyées sous forme de colonne de liste imbriquée à l'objet original.

On commence avec les données d'accessibilité, issues de Nelson et al. (2018)

```{r}
# On choisit le seuil de la distance aux villes de 5000 habitants et plus
Vahatra_poly <-  get_resources(x = Vahatra_poly, resource = "nelson_et_al",  
                               range_traveltime = "5k_110mio")
```

On peut visualiser le contenu de ces données.

```{r}
# On récupère le contour de Madagascar
mada <- gadm("MDG", level=0, path = "data") %>%
  st_as_sf()
# On charge les données de Nelson qu'on ne garde que sur l'emprise de Madagascar
nelson <- rast("data/mapme_biodiversity/nelson_et_al/traveltime-5k_110mio.tif") %>%
  crop(mada)
# On visualise les données
nelson %>%
  tm_shape() + 
  tm_raster(palette = "viridis",  style = "quantile", n = 20, colorNA = NULL) 
```

Puis calculer l'accessibilité moyenne pour chaque aire protégée.

```{r}
# Indicateurs d'accessibilité
Vahatra_poly <- calc_indicators(x = Vahatra_poly,
                                "traveltime",  stats_accessibility = "mean",
                                engine = "extract") 
```

On peut représenter le résultat dans une carte :

```{r}
Vahatra_poly %>%
  unnest(traveltime) %>%
  tm_shape() + 
  tm_fill(col = "minutes_mean")
```

# Données topologiques

Le jeu de données NASA/SRTM, ou "Shuttle Radar Topography Mission", est un ensemble de données topographiques de haute résolution capturé par le radar spatial de la navette spatiale Endeavour en février 2000. Cette mission, une collaboration entre la NASA et le National Geospatial-Intelligence Agency (NGA), avait pour objectif de cartographier la majeure partie de la Terre pour obtenir une représentation précise du relief terrestre. Les données SRTM couvrent la quasi-totalité de la surface terrestre entre les latitudes 60°N et 56°S, offrant une résolution spatiale de 30 mètres pour les données globales.

Grâce à ces données, il est possible d'évaluer l'altitude moyenne d'une aire spécifique. On peut aussi calculer le TRI (Topographic Ruggedness Index), qui quantifie la variation de l'altitude dans un paysage. Il est calculé en prenant la racine carrée de la somme des carrés des différences d'altitude entre une cellule et ses voisines. Un TRI élevé indique un terrain accidenté, tandis qu'un TRI faible suggère un terrain plus plat ou uniforme.

On utilise mapme.biodiversity pour calculer ces indices.

```{r}
# Modèle numérique de terrain SRTM de la NASA
Vahatra_poly <- get_resources(x = Vahatra_poly, resource = "nasa_srtm")

# Parallélisation pour accélérer le processus
# parallel::detectCores()
plan(multisession, workers = 6)

# Indicateurs de relief de terrain
progressr::with_progress({
Vahatra_poly <- calc_indicators(x = Vahatra_poly,
                                indicators = c("tri", "elevation"),
                                stats_tri = "mean", stats_elevation = "mean")
})
 
```

On peut représenter l'indice TRI (indiquant si le terrain est accidenté) moyen pour chaque aire protégée.

```{r}
Vahatra_poly %>%
  unnest(c(tri, elevation)) %>%
  tm_shape() + 
  tm_fill(col = "tri_mean")
```

# Faire la même chose pour les densités de populations

Les données "WorldPop" fournissent des estimations détaillées de la distribution de la population à l'échelle mondiale. Plutôt que de se baser uniquement sur les recensements traditionnels, qui peuvent être obsolètes ou inexacts, le projet WorldPop utilise des méthodes avancées de modélisation statistique en combinant des informations de recensement avec d'autres sources de données, telles que les images satellite, pour produire des cartes de densité de population à avec une résolution de 1km.

> Exercice : obtenez les ressources de worldpop et calculez la population par aire protégée.

```{r}
Vahatra_poly <- get_resources(x = Vahatra_poly, resource = "worldpop")

# Indicateurs de population
Vahatra_poly <- calc_indicators(x = Vahatra_poly,
                                indicators = "population_count", 
                                stats_popcount = "sum")

 
Vahatra_poly %>%
  unnest(population_count) %>%
  filter(year == 2000) %>%
  tm_shape() + 
  tm_fill(col = "popcount_sum") 
```

# Données de forêt

```{r}
Vahatra_poly <- get_resources(Vahatra_poly, c("gfw_treecover", "gfw_lossyear"))


# Indicateurs de couvert forestier
with_progress({
  Vahatra_poly  <- calc_indicators(x = Vahatra_poly,
                                   indicators = "treecover_area", 
                                   min_cover = 10, min_size = 1)
})
write_rds(Vahatra_poly, "Vahatra_poly.rds") # on enregistre une copie au cas où
```

# Mise en forme des résultats

Mapme.biodiversity produit généralement des résultats qui ont été "imbriqués", c'est-à-dire qu'une cellule du tableau contient elle-même un tableau. Pour les cas où le tableau inclus ne contient qu'une ligne (indicateur d'altitude, de terrain accidenté et de distance aux villes), on peut simplement utiliser la fonction `unnest()` qui extrait le contenu pour le placer dans une colonne. Pour les autres, il faut ajouter une étape :

-   Soit sélectionner l'année qui nous intéresse (c'est le cas pour la densité de population, on ne gardera que l'année 2000) ;

-   Soit faire ce qu'on appelle un "pivot" pour passer les valeurs de chaque année en colonne (c'est ce qu'on fera pour les données annuelles de couvert forestier)

```{r}
Vahatra_poly2 <- Vahatra_poly %>%
  unnest(c(traveltime, tri, elevation)) %>% # on déplie les indicateurs simples
  unnest(population_count) %>%
  filter(year == 2000) %>% # Pour la densité de population, on ne garde que 2000
  select(-year) %>% # On enlève la variable year
  rename(popcount_2000 = popcount_sum) %>%
  unnest(treecover_area) %>%
  as.data.frame() %>%
  pivot_wider(values_from = treecover, names_from = years,
              names_prefix = "treecover_") %>%
  st_sf()
```

> Exercice : Inspectez le contenu de Vahatra_poly2 et assurez-vous que vous ayez bien le bon résultat

```{r}
# On crée une fonction pour simplifier le calcul de moyennes pondérées


AP_Vahatra2 <- Vahatra_poly2 %>%
  group_by(nom, cat_iucn, creation, date_creation, date_modification, 
           mention_changement, num_atlas_, full_name, province, region, 
           district, gest_1, gest_2, type_ap, an_creation) %>%
  summarise(
    hectares_sum = sum(hectares),
    minutes_mean = weighted.mean(minutes_mean, hectares),
    tri_mean = weighted.mean(tri_mean, hectares),
    elevation_mean = weighted.mean(elevation_mean, hectares),
    popcount_2000 = sum(popcount_2000),
    across(starts_with("treecover"), sum)
  ) %>%
  ungroup()

write_rds(AP_Vahatra2, "data/AP_Vahatra2.rds")

```
